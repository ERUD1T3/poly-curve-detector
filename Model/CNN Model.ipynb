{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop the model for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6410f2319094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# All our imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# All our imports\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from random import randint\n",
    "#for all the plots to be inline\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Set manipulation'''\n",
    "\n",
    "# build dataset of multiplications \n",
    "DATASET_SIZE = 100000\n",
    "TESTSET_SIZE = 100\n",
    "RANGE = 10 # from 0 to 100\n",
    "LEARNING_RATE = .003\n",
    "\n",
    "\n",
    "# building the training set\n",
    "# dataset = np.zeros((DATASET_SIZE, 3), dtype=int)\n",
    "dataset_inputs_int = np.random.randint(low=-RANGE, high=RANGE, size=(DATASET_SIZE, 2)) # 2 because of pairs\n",
    "dataset_inputs = dataset_inputs_int.astype(np.float)\n",
    "dataset_labels = np.zeros((DATASET_SIZE, 1), dtype=float)\n",
    "\n",
    "# building the testing set\n",
    "testset_inputs_int = np.random.randint(low=-RANGE, high=RANGE, size=(TESTSET_SIZE, 2)) # 30% for testing\n",
    "testset_inputs = testset_inputs_int.astype(np.float)\n",
    "testset_labels = np.zeros((DATASET_SIZE, 1), dtype=float)\n",
    "\n",
    "#generate an array of the products\n",
    "for index in range(DATASET_SIZE):\n",
    "    # dataset[index,0] = randint(-10, 10)\n",
    "    # dataset[index,1] = randint(-10, 10)\n",
    "    # dataset[index,2] = dataset[index, 0] * dataset[index,1]\n",
    "    dataset_labels[index, 0] = dataset_inputs[index, 0] * dataset_inputs[index, 1]\n",
    "\n",
    "\n",
    "# print('dataset inputs\\n', dataset_inputs)\n",
    "# print('dataset labels\\n', dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # more analysis required to determine the specifics of the architecture\n",
    "        self.n_input = 96*96 \n",
    "        self.n_output = 8\n",
    "        \n",
    "#         imageInputLayer([28 28 1])\n",
    "#         convolution2dLayer(3,8,'Padding','same')\n",
    "#         batchNormalizationLayer\n",
    "#         reluLayer\n",
    "#         averagePooling2dLayer(2,'Stride',2)\n",
    "#         convolution2dLayer(3,16,'Padding','same')\n",
    "#         batchNormalizationLayer\n",
    "#         reluLayer\n",
    "#         averagePooling2dLayer(2,'Stride',2)\n",
    "#         convolution2dLayer(3,32,'Padding','same')\n",
    "#         batchNormalizationLayer\n",
    "#         reluLayer\n",
    "#         convolution2dLayer(3,32,'Padding','same')\n",
    "#         batchNormalizationLayer\n",
    "#         reluLayer\n",
    "#         dropoutLayer(0.2)\n",
    "#         fullyConnectedLayer(1)\n",
    "#         regressionLayer\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #feedword pass through our network\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(new_model, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model = new_model.Network(checkpoint['input_size'], \n",
    "            checkpoint['output_size'],\n",
    "            checkpoint['hidden_layers']\n",
    "            )\n",
    "\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def save(self):\n",
    "        self.checkpoint = {\n",
    "            'input_size': self.n_input, \n",
    "            'output_size': self.n_output,\n",
    "            'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        torch.save(self.checkpoint, 'checkpoint.pth')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images = images.resize_(images.size()[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            \n",
    "            # Flatten images into a 784 long vector\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
