{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop the model for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# All our imports\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from random import randint\n",
    "#for all the plots to be inline\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Set manipulation'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # more analysis required to determine the specifics of the architecture\n",
    "       \n",
    "        self.n_output = 8\n",
    "        self.n_channel = 1\n",
    "    \n",
    "        self.layers = nn.Sequential(\n",
    "#         imageInputLayer([28 28 1])\n",
    "#         convolution2dLayer(3,8,'Padding','same')\n",
    "        nn.Conv2d(1, 8, 3), \n",
    "#         batchNormalizationLayer\n",
    "        nn.BatchNorm2d(8),\n",
    "#         reluLayer\n",
    "        nn.LeakyReLU(),\n",
    "#         averagePooling2dLayer(2,'Stride',2)\n",
    "        nn.MaxPool2d(2, 2),\n",
    "#         convolution2dLayer(3,16,'Padding','same')\n",
    "        nn.Conv2d(8, 16, 3),\n",
    "#         batchNormalizationLayer\n",
    "        nn.BatchNorm2d(16),\n",
    "#         reluLayer\n",
    "        nn.LeakyReLU(),\n",
    "#         averagePooling2dLayer(2,'Stride',2)\n",
    "        nn.MaxPool2d(2, 2),\n",
    "#         convolution2dLayer(3,32,'Padding','same')\n",
    "        nn.Conv2d(16, 32, 3),\n",
    "#         batchNormalizationLayer\n",
    "        nn.BatchNorm2d(32),\n",
    "#         reluLayer\n",
    "        nn.LeakyReLU(),\n",
    "#         convolution2dLayer(3,32,'Padding','same')\n",
    "        nn.Conv2d(32, 32, 3),\n",
    "#         batchNormalizationLayer\n",
    "        nn.BatchNorm2d(32),\n",
    "#         reluLayer\n",
    "        nn.LeakyReLU(),\n",
    "#         Max pooling layer\n",
    "        nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.n_input = 96*96 \n",
    "        #TODO:actual value might be determined from the computed output of the cnn layers\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "#         fullyConnectedLayer(1)\n",
    "                nn.Linear(self.n_input, 1024),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(64, self.n_output),\n",
    "                nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "#         regressionLayer\n",
    "        self.criterion = nn.MSELoss()       \n",
    "#         dropoutLayer(0.2)\n",
    "        self.dropout =  nn.Dropout(p=0.2)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #feedword pass through our network\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.shape[0], -1) #flatten the input tensor\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(new_model, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model = new_model.Network(checkpoint['input_size'], \n",
    "            checkpoint['output_size'],\n",
    "            checkpoint['hidden_layers']\n",
    "            )\n",
    "\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def save(self):\n",
    "        self.checkpoint = {\n",
    "            'input_size': self.n_input, \n",
    "            'output_size': self.n_output,\n",
    "            'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        torch.save(self.checkpoint, 'checkpoint.pth')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images = images.resize_(images.size()[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "    \n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            \n",
    "            # Flatten images into a 784 long vector\n",
    "            images.resize_(images.size()[0], 784)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd3835964c07f68067958cda8891398bee6146e0c45f6e071fedf12c3d5007e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
