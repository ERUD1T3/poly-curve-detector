{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop the model for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our imports\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import PIL\n",
    "import os\n",
    "#for all the plots to be inline\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.values[index][0]\n",
    "        labels = np.array([1, 1, 1, 1, 1, 1, 1, 1])\n",
    "        for x in range(0, 8):\n",
    "            labels[x] = self.df.values[index][x+1]\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 -3  1  0 -9 -8 -6  5]\n",
      "[  4  -1 -10   0  10  -2  -7  10]\n"
     ]
    }
   ],
   "source": [
    "'''Data Set manipulation'''\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "root = \"C:\\\\Users\\\\the_3\\\\Desktop\"\n",
    "\n",
    "trainDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\DataGeneration\\\\plotData\\\\labels\\\\trainPlots.csv\",\n",
    "                               root + \"\\\\poly-curve-detector\\\\DataGeneration\\\\plotData\\\\trainPlots\", transform)\n",
    "\n",
    "testDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\DataGeneration\\\\plotData\\\\labels\\\\testPlots.csv\",\n",
    "                               root + \"\\\\poly-curve-detector\\\\DataGeneration\\\\plotData\\\\testPlots\", transform)\n",
    "\n",
    "#print first label in each dataset\n",
    "#labels in order [a1,a2,a3,a4,a5,a6,a7,a8]\n",
    "image, labels = trainDataset[0]\n",
    "print(labels[0:9])\n",
    "image, labels = testDataset[0]\n",
    "print(labels[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(trainDataset, shuffle=True, batch_size=128)\n",
    "test_set = torch.utils.data.DataLoader(testDataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # more analysis required to determine the specifics of the architecture\n",
    "       \n",
    "        self.n_output = 8\n",
    "        self.n_channel = 1\n",
    "    \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "        #         imageInputLayer([28 28 1])\n",
    "        #         convolution2dLayer(3,8,'Padding','same')\n",
    "                nn.Conv2d(1, 8, 3), \n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(8),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         averagePooling2dLayer(2,'Stride',2)\n",
    "                nn.MaxPool2d(2, 2),\n",
    "        #         convolution2dLayer(3,16,'Padding','same')\n",
    "                nn.Conv2d(8, 16, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(16),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         averagePooling2dLayer(2,'Stride',2)\n",
    "                nn.MaxPool2d(2, 2),\n",
    "        #         convolution2dLayer(3,32,'Padding','same')\n",
    "                nn.Conv2d(16, 32, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(32),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         convolution2dLayer(3,32,'Padding','same')\n",
    "                nn.Conv2d(32, 32, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(32),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         Max pooling layer\n",
    "                nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.n_input = 2592 # the output of maxpool 96*96 \n",
    "        #TODO:actual value might be determined from the computed output of the cnn layers\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "#         fullyConnectedLayer(1)\n",
    "                nn.Linear(self.n_input,  1024),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(64, self.n_output),\n",
    "                nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "#         regressionLayer\n",
    "        self.criterion = nn.MSELoss()       \n",
    "#         dropoutLayer(0.2)\n",
    "        self.dropout =  nn.Dropout(p=0.2)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #feedword pass through our network\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.shape[0], -1) #flatten the input tensor\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(new_model, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        # model = Network(\n",
    "        #         checkpoint['input_size'], \n",
    "        #         checkpoint['output_size'],\n",
    "        #         # checkpoint['cnn_layers'],\n",
    "        #         # checkpoint['fc_layers']\n",
    "        # )\n",
    "        new_model.load_state_dict(checkpoint['state_dict'])\n",
    "        return new_model\n",
    "    \n",
    "    def save(self, dirpath):\n",
    "        self.checkpoint = {\n",
    "            'input_size': self.n_input, \n",
    "            'output_size': self.n_output,\n",
    "        #     'cnn_layers': [each. for each in model.cnn_layers],\n",
    "        #     'fc_layers': [each.out_features for each in model.fc_layers],\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        torch.save(self.checkpoint, f'{dirpath}\\\\model_checkpoint.pth')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "        if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "        labels = labels.float()\n",
    "        images = images.to(device)\n",
    "        labels = images.to(device)\n",
    "\n",
    "\n",
    "\n",
    "        output = model.forward(images)\n",
    "\n",
    "        print(f'output={output.shape}')\n",
    "        print(f'label={labels.shape}')\n",
    "        test_loss += criterion(output, labels)\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "     \n",
    "    model.to(device)\n",
    "\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            # if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "            # Flatten images into a 784 long vector\n",
    "            # images = images.view(images.shape[0], -1)\n",
    "            labels = labels.float()\n",
    "            images.to(device)\n",
    "            labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            print(f'output={output.shape}')\n",
    "            print(f'label={labels.shape}')\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward() # computes gradient and backpropagation\n",
    "            optimizer.step() # update of weights and biases happenss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 96, 96]) torch.Size([128, 8])\n",
      "Train Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]]])\n",
      "Labels: tensor([ 0,  0,  0, 10, -3, -2,  6,  3], dtype=torch.int32)\n",
      "\n",
      "torch.Size([1, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 96, 96]) torch.Size([128, 8])\n",
      "Test Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]]])\n",
      "Labels: tensor([  4,  -1, -10,   0,  10,  -2,  -7,  10], dtype=torch.int32)\n",
      "\n",
      "torch.Size([1, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#one way to see batch size\n",
    "train_batch = next(iter(train_set))\n",
    "img, lbls = train_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in train_set\n",
    "#note: image changes each time run because shuffle is set to true\n",
    "for images, labels in train_set:\n",
    "    image = images[0]\n",
    "    label = labels[0]\n",
    "    print(f\"Train Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    break\n",
    "    \n",
    "#test batch size\n",
    "test_batch = next(iter(test_set))\n",
    "img, lbls = test_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in test_set\n",
    "for images, labels in test_set:\n",
    "    image = images[0]\n",
    "    label = labels[0]\n",
    "    print(f\"Test Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1118e-01, -4.8384e-04,  6.7642e-02,  ...,  3.5483e-02,\n",
      "         -1.2406e-04, -6.9609e-04],\n",
      "        [ 1.3927e-01, -4.5362e-04,  4.5116e-02,  ...,  3.4301e-02,\n",
      "          3.1027e-02, -6.5788e-04],\n",
      "        [ 1.2498e-01, -7.0234e-04,  5.4447e-02,  ...,  2.0629e-02,\n",
      "          1.2399e-02, -4.8112e-04],\n",
      "        ...,\n",
      "        [ 1.2444e-01, -5.5262e-04,  2.6013e-02,  ...,  1.4316e-02,\n",
      "          2.0556e-02, -6.9598e-04],\n",
      "        [ 1.3943e-01, -5.5677e-04, -7.6017e-05,  ...,  4.1190e-02,\n",
      "          1.0418e-02, -5.5658e-04],\n",
      "        [ 1.0276e-01, -8.3162e-04, -2.3545e-04,  ...,  5.0151e-02,\n",
      "          2.4738e-02, -3.4966e-04]], grad_fn=<LeakyReluBackward0>)\n",
      "tensor([[  4,  -1, -10,  ...,  -2,  -7,  10],\n",
      "        [  4,  -7,  -3,  ...,   0, -10,  -8],\n",
      "        [  1,  -8,  -5,  ...,  -8,  -7,   4],\n",
      "        ...,\n",
      "        [ -2,  10,   0,  ...,  -9, -10,   2],\n",
      "        [ -7,   9,   2,  ...,   0, -10,   7],\n",
      "        [ -3,  -1, -10,  ...,  -2,  -4,   3]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "output = model.forward(img)\n",
    "print(output)\n",
    "print(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1112, -0.0005,  0.0676, -0.0017,  0.0802,  0.0355, -0.0001, -0.0007],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output.shape)\n",
    "output[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE A: Train model on the data set\n",
    "    # DONE 1: dataloader be able load (image: tensor, label:string) example of the label tensor([10,-4,-5,3,-2,-3,-2,2]) \n",
    "    # DONE 2: fix dimensionality so the net can feedforward a batch of images correctly, move the training to gpu when available\n",
    "    # DONE 3: make trainloader and testloader dataloaders\n",
    "# TODO B: Improve model\n",
    "    # DONE 4: update checkpoint structure to save model and load model\n",
    "    #TODO 5: use better graphics to display the results (Josias)\n",
    "    #TODO 6: add a grid to the input like YOLO (hold)\n",
    "    #TODO 7: Build a list of ideas to improve the nework (Brandon and Josias)\n",
    "    #TODO 8: Find out if cnn layers learn (Josias)\n",
    "    #TODO 9: Fix the testloader issue where 8 size expected but found 96 (Brandon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 60.840..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 37.364..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 35.990..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 37.621..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 36.693..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 37.233..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 37.065..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 36.400..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 1/30..  Training Loss: 35.702..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 37.817..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 42.411..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 37.662..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 38.487..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 36.496..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 36.800..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 36.690..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 2/30..  Training Loss: 37.363..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 2/30..  Training Loss: 37.057..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 37.171..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 36.932..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 37.596..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 35.725..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 36.980..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 38.067..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 37.417..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 3/30..  Training Loss: 37.345..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 3/30..  Training Loss: 35.829..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 36.075..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 37.028..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 36.092..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 38.478..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 36.245..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 36.939..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 36.610..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 4/30..  Training Loss: 43.962..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 4/30..  Training Loss: 37.047..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 37.299..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 37.790..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 36.628..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 36.944..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 37.049..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 36.798..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 37.653..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 5/30..  Training Loss: 37.517..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 5/30..  Training Loss: 40.741..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 37.784..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 36.427..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 38.368..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 38.680..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 37.478..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 36.913..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 36.704..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 6/30..  Training Loss: 37.730..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 6/30..  Training Loss: 37.884..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 37.435..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 36.213..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 36.591..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 39.684..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 35.700..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 36.659..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 35.479..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 7/30..  Training Loss: 36.589..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 7/30..  Training Loss: 34.776..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 34.468..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.882..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.831..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 37.031..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.637..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.288..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.415..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 8/30..  Training Loss: 36.255..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([64, 8])\n",
      "label=torch.Size([64, 8])\n",
      "Epoch: 8/30..  Training Loss: 38.099..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 35.104..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 46.714..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 36.479..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 35.729..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 38.344..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 9/30..  Training Loss: 37.881..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9edca742ab84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrainloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtestloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-a3a7c1565c08>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, testloader, criterion, optimizer, epochs, print_every)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;31m# Turn off gradients for validation, will speed up inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
      "\u001b[1;32m<ipython-input-25-a3a7c1565c08>\u001b[0m in \u001b[0;36mvalidation\u001b[1;34m(model, testloader, criterion)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# images = images.view(images.shape[0], -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-87fb24477667>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2891\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model, \n",
    "    trainloader=train_set, \n",
    "    testloader=test_set, \n",
    "    criterion=model.criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=30, \n",
    "    print_every=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7029, -0.0289,  3.4589,  ...,  0.6749,  8.4575,  7.2477],\n",
      "        [-0.1617, -0.9054, -0.1270,  ..., -0.6929, -1.2862, -2.6740],\n",
      "        [-0.1521, -0.0855, -0.1045,  ..., -0.0853, -0.0598,  5.1148],\n",
      "        ...,\n",
      "        [-0.0262, -0.0745,  1.0990,  ..., -0.0378,  8.6809,  7.4096],\n",
      "        [ 4.7451,  0.7981,  4.3445,  ..., -0.0205,  4.9456, -0.0352],\n",
      "        [-0.7495, -2.0451, -0.7022,  ..., -1.4137, -2.4117, -5.7564]],\n",
      "       grad_fn=<LeakyReluBackward0>)\n",
      "tensor([[ 10,   5,  -6,  ...,  -7,   9,   8],\n",
      "        [  1,  10,   7,  ...,  -7,   0,  -6],\n",
      "        [ -4,   0,  -2,  ...,   6,  -6,   5],\n",
      "        ...,\n",
      "        [-10,  -7,   7,  ...,  -6,   5,   9],\n",
      "        [  8,   7,   6,  ...,   4,   4,  -7],\n",
      "        [  7,   5,  -1,  ...,  -8,   0, -10]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(img)\n",
    "print(output)\n",
    "print(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\the_3\\\\Desktop\\\\poly-curve-detector\\\\Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=2592, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Network()\n",
    "Network.load_checkpoint(new_model, \"C:\\\\Users\\\\the_3\\\\Desktop\\\\poly-curve-detector\\\\Model\\\\model_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a1829a56db40c3ca63cc5d173ccaf89ee3791672440d362287656aaeb413643"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
