{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop the model for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our imports\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import PIL\n",
    "import os\n",
    "#for all the plots to be inline\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.values[index][0]\n",
    "        labels = np.array([1, 1, 1, 1, 1, 1, 1, 1])\n",
    "        for x in range(0, 8):\n",
    "            labels[x] = self.df.values[index][x+1]\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 -3  1  0 -9 -8 -6  5]\n",
      "[  4  -1 -10   0  10  -2  -7  10]\n"
     ]
    }
   ],
   "source": [
    "'''Data Set manipulation'''\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "root = \"C:\\\\Users\\\\the_3\\\\Desktop\"\n",
    "\n",
    "trainDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\labels\\\\trainPlots.csv\",\n",
    "                               root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\trainPlots\", transform)\n",
    "\n",
    "testDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\labels\\\\testPlots.csv\",\n",
    "                               root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\testPlots\", transform)\n",
    "\n",
    "#print first label in each dataset\n",
    "#labels in order [a1,a2,a3,a4,a5,a6,a7,a8]\n",
    "image, labels = trainDataset[0]\n",
    "print(labels[0:9])\n",
    "image, labels = testDataset[0]\n",
    "print(labels[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(trainDataset, shuffle=True, batch_size=128)\n",
    "test_set = torch.utils.data.DataLoader(testDataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # more analysis required to determine the specifics of the architecture\n",
    "       \n",
    "        self.n_output = 8\n",
    "        self.n_channel = 1\n",
    "    \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "        #         imageInputLayer([28 28 1])\n",
    "        #         convolution2dLayer(3,8,'Padding','same')\n",
    "                nn.Conv2d(1, 8, 3), \n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(8),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         averagePooling2dLayer(2,'Stride',2)\n",
    "                nn.MaxPool2d(2, 2),\n",
    "        #         convolution2dLayer(3,16,'Padding','same')\n",
    "                nn.Conv2d(8, 16, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(16),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         averagePooling2dLayer(2,'Stride',2)\n",
    "                nn.MaxPool2d(2, 2),\n",
    "        #         convolution2dLayer(3,32,'Padding','same')\n",
    "                nn.Conv2d(16, 32, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(32),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         convolution2dLayer(3,32,'Padding','same')\n",
    "                nn.Conv2d(32, 32, 3),\n",
    "        #         batchNormalizationLayer\n",
    "                nn.BatchNorm2d(32),\n",
    "        #         reluLayer\n",
    "                nn.LeakyReLU(),\n",
    "        #         Max pooling layer\n",
    "                nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.n_input = 2592 # the output of maxpool 96*96 \n",
    "        #TODO:actual value might be determined from the computed output of the cnn layers\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "#         fullyConnectedLayer(1)\n",
    "                nn.Linear(self.n_input,  1024),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(1024, 256),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(64, self.n_output),\n",
    "                nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "#         regressionLayer\n",
    "        self.criterion = nn.MSELoss()       \n",
    "#         dropoutLayer(0.2)\n",
    "        self.dropout =  nn.Dropout(p=0.2)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #feedword pass through our network\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.shape[0], -1) #flatten the input tensor\n",
    "        x = self.fc_layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(new_model, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        # model = Network(\n",
    "        #         checkpoint['input_size'], \n",
    "        #         checkpoint['output_size'],\n",
    "        #         # checkpoint['cnn_layers'],\n",
    "        #         # checkpoint['fc_layers']\n",
    "        # )\n",
    "        new_model.load_state_dict(checkpoint['state_dict'])\n",
    "        return new_model\n",
    "    \n",
    "    def save(self, dirpath):\n",
    "        self.checkpoint = {\n",
    "            'input_size': self.n_input, \n",
    "            'output_size': self.n_output,\n",
    "        #     'cnn_layers': [each. for each in model.cnn_layers],\n",
    "        #     'fc_layers': [each.out_features for each in model.fc_layers],\n",
    "            'state_dict': model.state_dict()\n",
    "        }\n",
    "        torch.save(self.checkpoint, f'{dirpath}\\\\model_checkpoint.pth')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "        if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "        labels = labels.float()\n",
    "        images = images.to(device)\n",
    "        labels = images.to(device)\n",
    "\n",
    "\n",
    "\n",
    "        output = model.forward(images)\n",
    "\n",
    "        print(f'output={output.shape}')\n",
    "        print(f'label={labels.shape}')\n",
    "        test_loss += criterion(output, labels)\n",
    "\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "     \n",
    "    model.to(device)\n",
    "\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            # if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "            # Flatten images into a 784 long vector\n",
    "            # images = images.view(images.shape[0], -1)\n",
    "            labels = labels.float()\n",
    "            images.to(device)\n",
    "            labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            print(f'output={output.shape}')\n",
    "            print(f'label={labels.shape}')\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward() # computes gradient and backpropagation\n",
    "            optimizer.step() # update of weights and biases happenss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 96, 96]) torch.Size([128, 8])\n",
      "Train Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]]])\n",
      "Labels: tensor([-10,  -5,   5,  -9,   7,   9,   5,   8], dtype=torch.int32)\n",
      "\n",
      "torch.Size([1, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 96, 96]) torch.Size([128, 8])\n",
      "Test Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]]])\n",
      "Labels: tensor([  4,  -1, -10,   0,  10,  -2,  -7,  10], dtype=torch.int32)\n",
      "\n",
      "torch.Size([1, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#one way to see batch size\n",
    "train_batch = next(iter(train_set))\n",
    "img, lbls = train_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in train_set\n",
    "#note: image changes each time run because shuffle is set to true\n",
    "for images, labels in train_set:\n",
    "    image = images[0]\n",
    "    label = labels[0]\n",
    "    print(f\"Train Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    break\n",
    "    \n",
    "#test batch size\n",
    "test_batch = next(iter(test_set))\n",
    "img, lbls = test_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in test_set\n",
    "for images, labels in test_set:\n",
    "    image = images[0]\n",
    "    label = labels[0]\n",
    "    print(f\"Test Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0022e-03,  3.9871e-02,  1.6699e-01,  ..., -1.5142e-03,\n",
      "         -6.0421e-05,  5.1141e-02],\n",
      "        [-1.3903e-03,  4.3438e-02,  1.2441e-01,  ..., -1.2619e-03,\n",
      "          3.4569e-03,  6.3358e-02],\n",
      "        [-7.9522e-04,  1.8441e-02,  1.4505e-01,  ..., -1.2043e-03,\n",
      "          2.5197e-02,  7.1434e-02],\n",
      "        ...,\n",
      "        [-9.9370e-04,  8.6166e-03,  1.6536e-01,  ..., -1.1998e-03,\n",
      "          3.4140e-02,  3.5715e-02],\n",
      "        [-8.2576e-04, -3.0264e-05,  1.4463e-01,  ..., -1.0896e-03,\n",
      "         -8.9830e-05,  8.1615e-02],\n",
      "        [-9.6996e-04, -2.1412e-04,  1.8107e-01,  ..., -1.2249e-03,\n",
      "         -1.4368e-05,  2.2369e-02]], grad_fn=<LeakyReluBackward0>)\n",
      "tensor([[  4,  -1, -10,  ...,  -2,  -7,  10],\n",
      "        [  4,  -7,  -3,  ...,   0, -10,  -8],\n",
      "        [  1,  -8,  -5,  ...,  -8,  -7,   4],\n",
      "        ...,\n",
      "        [ -2,  10,   0,  ...,  -9, -10,   2],\n",
      "        [ -7,   9,   2,  ...,   0, -10,   7],\n",
      "        [ -3,  -1, -10,  ...,  -2,  -4,   3]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "output = model.forward(img)\n",
    "print(output)\n",
    "print(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0022e-03,  3.9871e-02,  1.6699e-01, -1.6425e-04,  6.5738e-02,\n",
       "        -1.5142e-03, -6.0421e-05,  5.1141e-02], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output.shape)\n",
    "output[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE A: Train model on the data set\n",
    "    # DONE 1: dataloader be able load (image: tensor, label:string) example of the label tensor([10,-4,-5,3,-2,-3,-2,2]) \n",
    "    # DONE 2: fix dimensionality so the net can feedforward a batch of images correctly, move the training to gpu when available\n",
    "    # DONE 3: make trainloader and testloader dataloaders\n",
    "# TODO B: Improve model\n",
    "    # DONE 4: update checkpoint structure to save model and load model\n",
    "    #TODO 5: use better graphics to display the results (Josias)\n",
    "    #TODO 6: add a grid to the input like YOLO (hold)\n",
    "    #TODO 7: Build a list of ideas to improve the nework (Brandon and Josias)\n",
    "    #TODO 8: Find out if cnn layers learn (Josias)\n",
    "    #TODO 9: Fix the testloader issue where 8 size expected but found 96 (Brandon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 35.798..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 35.901..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 41.213..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 36.514..  Test Loss: 0.000..  Test Accuracy: 0.000\n",
      "output=torch.Size([128, 8])\n",
      "label=torch.Size([128, 8])\n",
      "Epoch: 1/30..  Training Loss: 35.491..  Test Loss: 0.000..  Test Accuracy: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9edca742ab84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtrainloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtestloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a3a7c1565c08>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, testloader, criterion, optimizer, epochs, print_every)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'output={output.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'label={labels.shape}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-94158e5bedf5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m#feedword pass through our network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#flatten the input tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2281\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model, \n",
    "    trainloader=train_set, \n",
    "    testloader=test_set, \n",
    "    criterion=model.criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=30, \n",
    "    print_every=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.7029, -0.0289,  3.4589,  ...,  0.6749,  8.4575,  7.2477],\n",
      "        [-0.1617, -0.9054, -0.1270,  ..., -0.6929, -1.2862, -2.6740],\n",
      "        [-0.1521, -0.0855, -0.1045,  ..., -0.0853, -0.0598,  5.1148],\n",
      "        ...,\n",
      "        [-0.0262, -0.0745,  1.0990,  ..., -0.0378,  8.6809,  7.4096],\n",
      "        [ 4.7451,  0.7981,  4.3445,  ..., -0.0205,  4.9456, -0.0352],\n",
      "        [-0.7495, -2.0451, -0.7022,  ..., -1.4137, -2.4117, -5.7564]],\n",
      "       grad_fn=<LeakyReluBackward0>)\n",
      "tensor([[ 10,   5,  -6,  ...,  -7,   9,   8],\n",
      "        [  1,  10,   7,  ...,  -7,   0,  -6],\n",
      "        [ -4,   0,  -2,  ...,   6,  -6,   5],\n",
      "        ...,\n",
      "        [-10,  -7,   7,  ...,  -6,   5,   9],\n",
      "        [  8,   7,   6,  ...,   4,   4,  -7],\n",
      "        [  7,   5,  -1,  ...,  -8,   0, -10]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "output = model.forward(img)\n",
    "print(output)\n",
    "print(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\\\Users\\\\the_3\\\\Desktop\\\\poly-curve-detector\\\\Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.01)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=2592, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Network()\n",
    "Network.load_checkpoint(new_model, \"C:\\\\Users\\\\the_3\\\\Desktop\\\\poly-curve-detector\\\\Model\\\\model_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a1829a56db40c3ca63cc5d173ccaf89ee3791672440d362287656aaeb413643"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
