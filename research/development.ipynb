{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop the model for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of ideas to improve the network\n",
    "\n",
    "0. ## start with easier polynomials\n",
    "1. ## Add a grid with finer blocks to the input as transform\n",
    "2. ## Revise the architecture\n",
    "3. ## Add dropout to the network\n",
    "4. ## Find a way to measure accuracy of multiple regression network with some tolerance factor, as well as explore statiscal measure of error such as standard deviation, p-value, r-square etc\n",
    "5. ## apply crossvalidation to the training loop\n",
    "6. ## List all hyperparameters of the network (affecting net performance)\n",
    "    >### Learning rate, number of epochs, batch size, Dropout rate\n",
    "    >### Loss function, Optimizer, Network architecture\n",
    "    >### CNN layers NofElement, arrangment, and parameters\n",
    "    >### FC layers NofElement, arrangment, and parameters\n",
    "7. ## Build a much larger much richer dataset with transforms to more than 10^5 sample, that is statistically sound (no extreme bias, etc...)\n",
    "8. ## Apply planned data augmentation transforms\n",
    "<!-- 9. ## Use a genetic algorithm to search best set of hyper parameters \n",
    "    >### Encode all hyperparameters listed into a string represention \"chromosome/gene\"\n",
    "    >### Use the new measure of accuracy to gauge the \"fitness\" of the net\n",
    "    >### Design a function to allow for \"crossover\" between nets' genes \n",
    "    >### Design a \"mutation\" function that allows for variations in hyperparameters.\n",
    "    >### Put the environment together to run the algorithm\n",
    "  -->\n",
    "9. ## Explore Self-Attention and Auto-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our imports\n",
    "import torch \n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import PIL\n",
    "import os\n",
    "\n",
    "#for all the plots to be inline\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, images_folder, transform):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename = self.df.values[index][0]\n",
    "        labels = np.array([1, 1, 1, 1, 1, 1, 1, 1])\n",
    "        for x in range(0, 8):\n",
    "            labels[x] = self.df.values[index][x+1]\n",
    "        image = PIL.Image.open(os.path.join(self.images_folder, filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Select device to train on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/erud1t3/Desktop/poly-curve-detector/data/plotData/labels/trainPlots.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-10db4e01f68f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# linux paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/erud1t3/Desktop\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m trainDataset = CustomDataset(root + \"/poly-curve-detector/data/plotData/labels/trainPlots.csv\",\n\u001b[0m\u001b[1;32m     19\u001b[0m                                root + \"/poly-curve-detector/data/plotData/trainPlots\", transform)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f03e8c3df862>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_path, images_folder, transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/erud1t3/Desktop/poly-curve-detector/data/plotData/labels/trainPlots.csv'"
     ]
    }
   ],
   "source": [
    "'''Data Set manipulation'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# windows pathss\n",
    "# root = \"C:\\\\Users\\\\the_3\\Desktop\"\n",
    "# trainDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\labels\\\\trainPlots.csv\",\n",
    "#                                root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\trainPlots\", transform)\n",
    "\n",
    "# testDataset = CustomDataset(root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\labels\\\\testPlots.csv\",\n",
    "#                                root + \"\\\\poly-curve-detector\\\\data\\\\plotData\\\\testPlots\", transform)\n",
    "\n",
    "\n",
    "# linux paths\n",
    "root = \"/home/erud1t3/Desktop\"\n",
    "trainDataset = CustomDataset(root + \"/poly-curve-detector/data/plotData/labels/trainPlots.csv\",\n",
    "                               root + \"/poly-curve-detector/data/plotData/trainPlots\", transform)\n",
    "\n",
    "testDataset = CustomDataset(root + \"/poly-curve-detector/data/plotData/labels/testPlots.csv\",\n",
    "                               root + \"/poly-curve-detector/data/plotData/testPlots\", transform)\n",
    "\n",
    "#print first label in each dataset\n",
    "#labels in order [a1,a2,a3,a4,a5,a6,a7,a8]\n",
    "# image, labels = trainDataset[0]\n",
    "# print(labels[0:9])\n",
    "# image, labels = testDataset[0]\n",
    "# print(labels[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(trainDataset, shuffle=True, batch_size=128)\n",
    "test_set = torch.utils.data.DataLoader(testDataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4, 96, 96]) torch.Size([128, 8])\n",
      "Train Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])\n",
      "Labels: tensor([ 6,  0,  1,  1, -5,  7,  5, -9], dtype=torch.int32)\n",
      "\n",
      "torch.Size([4, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4, 96, 96]) torch.Size([128, 8])\n",
      "Test Set 0\n",
      "Image: tensor([[[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         ...,\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.8235, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 0.8235],\n",
      "         [0.6745, 0.8235, 0.8235,  ..., 0.8235, 0.8235, 0.6745]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])\n",
      "Labels: tensor([ 0, -6, -5,  0,  8, -1,  7,  7], dtype=torch.int32)\n",
      "\n",
      "torch.Size([4, 96, 96]) torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#one way to see batch size\n",
    "train_batch = next(iter(train_set))\n",
    "img, lbls = train_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in train_set\n",
    "#note: image changes each time run because shuffle is set to true\n",
    "for images, labels in train_set:\n",
    "    image, label = images[0], labels[0]\n",
    "    print(f\"Train Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break\n",
    "    \n",
    "#test batch size\n",
    "test_batch = next(iter(test_set))\n",
    "img, lbls = test_batch\n",
    "print(img.shape, lbls.shape)\n",
    "\n",
    "#display the first image in test_set\n",
    "for images, labels in test_set:\n",
    "    image, label = images[0], labels[0]\n",
    "    print(f\"Test Set 0\\nImage: {image}\\nLabels: {label}\\n\")\n",
    "    print(image.shape, label.shape)\n",
    "    figure = plt.figure(figsize=(4,4))\n",
    "    figure.add_subplot()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.permute(1,2,0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Network, self).__init__()\n",
    "#         # more analysis required to determine the specifics of the architecture\n",
    "       \n",
    "#         self.n_output = 8\n",
    "#         self.n_channel = 1\n",
    "    \n",
    "#         self.cnn_layers = nn.Sequential(\n",
    "#                 nn.Conv2d(1, 8, 3), # convolution2dLayer(3,8,'Padding','same')\n",
    "#                 nn.BatchNorm2d(8),   # batchNormalizationLayer\n",
    "#                 nn.LeakyReLU(), # reluLayer\n",
    "#                 nn.MaxPool2d(2, 2), # averagePooling2dLayer(2,'Stride',2)\n",
    "#                 nn.Conv2d(8, 16, 3), # convolution2dLayer(3,16,'Padding','same')\n",
    "#                 nn.BatchNorm2d(16), # batchNormalizationLayer\n",
    "#                 nn.LeakyReLU(), # reluLayer\n",
    "#                 nn.MaxPool2d(2, 2), # averagePooling2dLayer(2,'Stride',2)\n",
    "#                 nn.Conv2d(16, 32, 3), # convolution2dLayer(3,32,'Padding','same')\n",
    "#                 nn.BatchNorm2d(32), # batchNormalizationLayer\n",
    "#                 nn.LeakyReLU(), # reluLayer\n",
    "#                 nn.Conv2d(32, 32, 3), # convolution2dLayer(3,32,'Padding','same')\n",
    "#                 nn.Conv2d(32, 32, 3), # convolution2dLayer(3,32,'Padding','same')\n",
    "#                 nn.Conv2d(32, 32, 3), # convolution2dLayer(3,32,'Padding','same')\n",
    "#                 nn.BatchNorm2d(32), # batchNormalizationLayer\n",
    "#                 nn.LeakyReLU(), # reluLayer\n",
    "#                 nn.MaxPool2d(2, 2) # Max pooling layer\n",
    "#         )\n",
    "\n",
    "#         self.n_input = 1568 # the output of maxpool 96*96 \n",
    "#         #DONE:actual value might be determined from the computed output of the cnn layers\n",
    "#         # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "\n",
    "#         self.fc_layers = nn.Sequential(\n",
    "#         #   fullyConnectedLayer(1)\n",
    "#             nn.Linear(self.n_input,  4096),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Dropout(p=.5),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Dropout(p=.3),\n",
    "#             nn.Linear(4096, 128),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Dropout(p=.3),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Dropout(p=.1),\n",
    "#             nn.Linear(64, self.n_output),\n",
    "#             nn.LeakyReLU()\n",
    "#         )\n",
    "\n",
    "\n",
    "# #         regressionLayer\n",
    "#         self.criterion = nn.MSELoss()       \n",
    "# #    \n",
    "\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         #feedword pass through our network\n",
    "#         x = self.cnn_layers(x)\n",
    "#         x = x.view(x.shape[0], -1) #flatten the input tensor\n",
    "#         x = self.fc_layers(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "\n",
    "#     @staticmethod\n",
    "#     def load_checkpoint(new_model, filepath):\n",
    "#         checkpoint = torch.load(filepath)\n",
    "#         # model = checkpoint['model']\n",
    "#         new_model.load_state_dict(checkpoint['state_dict'])\n",
    "#         return new_model\n",
    "    \n",
    "#     def save(self, dirpath):\n",
    "#         self.checkpoint = {\n",
    "#         #     'input_size': self.n_input, \n",
    "#         #     'output_size': self.n_output,\n",
    "#         #     'cnn_layers': [each. for each in model.cnn_layers],\n",
    "#         #     'fc_layers': [each.out_features for each in model.fc_layers],\n",
    "#             'state_dict': model.state_dict()\n",
    "#         }\n",
    "#         torch.save(self.checkpoint, f'{dirpath}\\\\model_checkpoint.pth')\n",
    "\n",
    "# model = Network() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer learning approach\n",
    "model = models.densenet121(pretrained=True)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "fc_layers = nn.Sequential(\n",
    "#   fullyConnectedLayer(1)\n",
    "  nn.Linear(1024,  1024),\n",
    "  nn.LeakyReLU(),\n",
    "  nn.Dropout(p=.5),\n",
    "  nn.Linear(1024, 512),\n",
    "  nn.LeakyReLU(),\n",
    "  nn.Dropout(p=.3),\n",
    "  nn.Linear(512, 8),\n",
    "  nn.LeakyReLU()\n",
    ")\n",
    "# classifier = nn.Sequential(\n",
    "#   nn.Linear(25088, 4096),\n",
    "#   nn.ReLU(),\n",
    "#   nn.Dropout(.5),\n",
    "#   nn.Linear(4096, 102),\n",
    "#   nn.LogSoftmax(dim=1)\n",
    "# )\n",
    "    \n",
    "model.classifier = fc_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure of accuracy\n",
    "# create a nn class (from https://discuss.pytorch.org/t/rmse-loss-function/16540/3)\n",
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        rmse = torch.sqrt(self.mse(yhat,y))\n",
    "        rmse_norm = rmse / 20.\n",
    "        return 100 (1 - rmse_norm)\n",
    "\n",
    "# criterion = RMSELoss()\n",
    "# loss = criterion(yhat,y)\n",
    "\n",
    "# Formula for Percent Accuracy\n",
    "# In an experiment observing a parameter with an accepted \n",
    "# value of VA and an observed value VO, there are two basic\n",
    "#  formulas for percent accuracy:\n",
    "\n",
    "# (VA - VO)/VA X 100 = percent accuracy\n",
    "\n",
    "# https://pytorch.org/ignite/generated/ignite.contrib.metrics.regression.R2Score.html\n",
    "\n",
    "rsme_accuracy = Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def validation(model, testloader, criterion):\n",
    "    accuracy = 0\n",
    "    test_loss = 0\n",
    "    for images, labels in testloader:\n",
    "        # if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "        # images = images.view(images.shape[0], -1)\n",
    "        labels = labels.float()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        output = model.forward(images)\n",
    "\n",
    "        # print(f'output={output.shape}')\n",
    "        # print(f'label={labels.shape}')\n",
    "        test_loss += criterion(output, labels)\n",
    "        accuracy += rsme_accuracy(output, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # ps = torch.exp(output)\n",
    "        # top_p, top_class = ps.topk(1, dim=1)\n",
    "        # equals = top_class == labels.view(*top_class.shape)\n",
    "        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "        # accuracy += 1 - test_loss\n",
    "        ## Calculating the accuracy \n",
    "        # Model's output is log-softmax, take exponential to get the probabilities\n",
    "        # ps = torch.exp(output)\n",
    "        # Class with highest probability is our predicted class, compare with true label\n",
    "        # equality = (labels.data == ps.max(1)[1])\n",
    "        # Accuracy is number of correct predictions divided by all predictions, just take the mean\n",
    "        # accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
    "        # accuracy = r2_score(labels, output)   # r2_score is the scikit learn r2 score function.\n",
    "        # print(\"accuracy = \", accuracy)   # here i get wierd values and it doesn't get better over time, in contrast the loss decreased over time\n",
    "\n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=5, print_every=40):\n",
    "\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    test_losses = []\n",
    "    train_losses = []\n",
    "    for e in range(epochs):\n",
    "        # Model in training mode, dropout is on\n",
    "        model.train()\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            # if(labels.shape != torch.Size([128, 1, 96, 96])): continue\n",
    "            # Flatten images into a 784 long vector\n",
    "            # images = images.view(images.shape[0], -1)\n",
    "            labels = labels.float()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model.forward(images)\n",
    "            # print(f'output={output.shape}')\n",
    "            # print(f'label={labels.shape}')\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward() # computes gradient and backpropagation\n",
    "            optimizer.step() # update of weights and biases happenss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                # Model in inference mode, dropout is off\n",
    "                model.eval()\n",
    "                \n",
    "                # Turn off gradients for validation, will speed up inference\n",
    "                with torch.no_grad():\n",
    "                    test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "                print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                      \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader))\n",
    "                      )\n",
    "                \n",
    "                running_loss = 0\n",
    "                \n",
    "                # Make sure dropout and grads are on for training\n",
    "                model.train()\n",
    "    plt.ylim([0, 50])          \n",
    "    plt.plot(train_losses, label='Training loss')\n",
    "    plt.plot(test_losses, label='Validation loss')\n",
    "    plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1500..  Training Loss: 36.655..  Test Loss: 36.937.. \n",
      "Epoch: 1/1500..  Training Loss: 35.877..  Test Loss: 36.860.. \n",
      "Epoch: 1/1500..  Training Loss: 34.431..  Test Loss: 36.936.. \n",
      "Epoch: 2/1500..  Training Loss: 34.289..  Test Loss: 36.296.. \n",
      "Epoch: 2/1500..  Training Loss: 33.713..  Test Loss: 35.743.. \n",
      "Epoch: 2/1500..  Training Loss: 32.695..  Test Loss: 35.317.. \n",
      "Epoch: 3/1500..  Training Loss: 32.606..  Test Loss: 33.741.. \n",
      "Epoch: 3/1500..  Training Loss: 31.772..  Test Loss: 32.736.. \n",
      "Epoch: 3/1500..  Training Loss: 32.811..  Test Loss: 32.081.. \n",
      "Epoch: 3/1500..  Training Loss: 31.766..  Test Loss: 31.643.. \n",
      "Epoch: 4/1500..  Training Loss: 31.014..  Test Loss: 31.626.. \n",
      "Epoch: 4/1500..  Training Loss: 31.569..  Test Loss: 31.546.. \n",
      "Epoch: 4/1500..  Training Loss: 31.297..  Test Loss: 31.312.. \n",
      "Epoch: 5/1500..  Training Loss: 31.776..  Test Loss: 31.395.. \n",
      "Epoch: 5/1500..  Training Loss: 31.435..  Test Loss: 31.226.. \n",
      "Epoch: 5/1500..  Training Loss: 31.094..  Test Loss: 30.983.. \n",
      "Epoch: 5/1500..  Training Loss: 30.703..  Test Loss: 31.042.. \n",
      "Epoch: 6/1500..  Training Loss: 30.514..  Test Loss: 30.997.. \n",
      "Epoch: 6/1500..  Training Loss: 30.947..  Test Loss: 30.709.. \n",
      "Epoch: 6/1500..  Training Loss: 30.155..  Test Loss: 30.772.. \n",
      "Epoch: 7/1500..  Training Loss: 29.969..  Test Loss: 30.926.. \n",
      "Epoch: 7/1500..  Training Loss: 29.954..  Test Loss: 30.825.. \n",
      "Epoch: 7/1500..  Training Loss: 30.016..  Test Loss: 30.470.. \n",
      "Epoch: 8/1500..  Training Loss: 30.599..  Test Loss: 30.643.. \n",
      "Epoch: 8/1500..  Training Loss: 29.872..  Test Loss: 30.558.. \n",
      "Epoch: 8/1500..  Training Loss: 29.977..  Test Loss: 30.400.. \n",
      "Epoch: 8/1500..  Training Loss: 29.278..  Test Loss: 30.425.. \n",
      "Epoch: 9/1500..  Training Loss: 29.521..  Test Loss: 30.232.. \n",
      "Epoch: 9/1500..  Training Loss: 28.977..  Test Loss: 30.326.. \n",
      "Epoch: 9/1500..  Training Loss: 28.946..  Test Loss: 30.439.. \n",
      "Epoch: 10/1500..  Training Loss: 29.108..  Test Loss: 30.308.. \n",
      "Epoch: 10/1500..  Training Loss: 29.216..  Test Loss: 30.394.. \n",
      "Epoch: 10/1500..  Training Loss: 28.160..  Test Loss: 30.170.. \n",
      "Epoch: 10/1500..  Training Loss: 28.986..  Test Loss: 30.033.. \n",
      "Epoch: 11/1500..  Training Loss: 28.489..  Test Loss: 30.054.. \n",
      "Epoch: 11/1500..  Training Loss: 29.026..  Test Loss: 30.084.. \n",
      "Epoch: 11/1500..  Training Loss: 28.112..  Test Loss: 30.065.. \n",
      "Epoch: 12/1500..  Training Loss: 28.326..  Test Loss: 30.052.. \n",
      "Epoch: 12/1500..  Training Loss: 27.921..  Test Loss: 30.234.. \n",
      "Epoch: 12/1500..  Training Loss: 28.099..  Test Loss: 30.042.. \n",
      "Epoch: 13/1500..  Training Loss: 28.084..  Test Loss: 29.905.. \n",
      "Epoch: 13/1500..  Training Loss: 27.554..  Test Loss: 29.845.. \n",
      "Epoch: 13/1500..  Training Loss: 27.958..  Test Loss: 29.719.. \n",
      "Epoch: 13/1500..  Training Loss: 28.096..  Test Loss: 29.922.. \n",
      "Epoch: 14/1500..  Training Loss: 27.659..  Test Loss: 29.999.. \n",
      "Epoch: 14/1500..  Training Loss: 27.341..  Test Loss: 29.934.. \n",
      "Epoch: 14/1500..  Training Loss: 27.781..  Test Loss: 29.803.. \n",
      "Epoch: 15/1500..  Training Loss: 27.355..  Test Loss: 29.870.. \n",
      "Epoch: 15/1500..  Training Loss: 27.274..  Test Loss: 29.797.. \n",
      "Epoch: 15/1500..  Training Loss: 27.258..  Test Loss: 29.891.. \n",
      "Epoch: 15/1500..  Training Loss: 27.330..  Test Loss: 29.890.. \n",
      "Epoch: 16/1500..  Training Loss: 27.222..  Test Loss: 29.957.. \n",
      "Epoch: 16/1500..  Training Loss: 26.823..  Test Loss: 29.670.. \n",
      "Epoch: 16/1500..  Training Loss: 26.728..  Test Loss: 29.856.. \n",
      "Epoch: 17/1500..  Training Loss: 26.961..  Test Loss: 29.992.. \n",
      "Epoch: 17/1500..  Training Loss: 26.537..  Test Loss: 29.997.. \n",
      "Epoch: 17/1500..  Training Loss: 26.717..  Test Loss: 29.642.. \n",
      "Epoch: 18/1500..  Training Loss: 26.114..  Test Loss: 29.842.. \n",
      "Epoch: 18/1500..  Training Loss: 26.561..  Test Loss: 29.567.. \n",
      "Epoch: 18/1500..  Training Loss: 26.168..  Test Loss: 29.563.. \n",
      "Epoch: 18/1500..  Training Loss: 26.663..  Test Loss: 29.887.. \n",
      "Epoch: 19/1500..  Training Loss: 25.723..  Test Loss: 29.801.. \n",
      "Epoch: 19/1500..  Training Loss: 26.412..  Test Loss: 29.594.. \n",
      "Epoch: 19/1500..  Training Loss: 25.653..  Test Loss: 29.204.. \n",
      "Epoch: 20/1500..  Training Loss: 26.419..  Test Loss: 29.447.. \n",
      "Epoch: 20/1500..  Training Loss: 25.827..  Test Loss: 29.582.. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-7c14faf491b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m train(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrainloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-2ca398b0f937>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainloader, testloader, criterion, optimizer, epochs, print_every)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;31m# Turn off gradients for validation, will speed up inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-2ca398b0f937>\u001b[0m in \u001b[0;36mvalidation\u001b[1;34m(model, testloader, criterion)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# print(f'output={output.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, init_features)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mnew_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_checkpoint_bottleneck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mbottleneck_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mnew_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py\u001b[0m in \u001b[0;36mbn_function\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbn_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mconcated_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mbottleneck_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcated_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: T484\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbottleneck_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2281\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = Network()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train(\n",
    "    model=model, \n",
    "    trainloader=train_set, \n",
    "    testloader=test_set, \n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer=optim.Adam(model.classifier.parameters(), lr=.001),\n",
    "    epochs=1500, \n",
    "    print_every=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor: [-3.87777   -8.17044   -2.713652  -1.1534442  6.125683  -0.8528877\n",
      "  6.036647   6.5977316]\n",
      "Output curve: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label tensor: [ 0 -6 -5  0  8 -1  7  7]\n",
      "Actual curve: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ6ElEQVR4nO3dS2xUVeDH8d9MaaEFOlSsUqD/P4QWmLGFP05tQzQaI8bEEBPDlshCfCS6IJGtiXGhceWKuJEYQjS6UeLCGF9oSBRIB8FCp0iRR4kNlNIHLX3OnP+CDLb0Ne38zpw7h98n6YaZufc4ma/n3DuPGzLGQESCJ+x6ACIyPcUpElCKUySgFKdIQClOkYBaNNuNDz/8sFm3bh19pxcuXEBtbS19uzZkM9bW1laUlJSgpqYmT6OaGfO57e/vx4ULF7Bp0yYsW7aMss2JCul1ANgbbyKRuGmMqZxygzFmxr94PG5siMcbrGzXhmzGum3bNrNz5848jGZuzOf2u+++MwDM8ePHaducqJBeB8bYGy+AZjNNf1rWEoRCIRgP3y8eHx8HACxaNOsCSyxRnAS+x1lUVOR4JA8mxUnga5ypVAqAZk5XFCeBr3FqWeuW4iTwPU4ta91QnAS+xqllrVuKk8DXOLWsdUtxEihOsUFxEvgep4453VCcBL7GqWNOtxQnga9xalnrluIk8D1OLWvdUJwEvsapZa1bipPA1zi1rHVLcRL4Hmc4rJeJC3rWCXyNM5VKoaioCKFQyPVQHkiKk8DXOMfHx7WkdUhxEihOsUFxEvgcp95GcUdxEvgaZyqV0szpUGi2F1UkEjG1tRvpO00mk4hGo/Tt2pDNWC9c+BupVAqbN7v/b2I+t1euXEFvbw+2bv0/yvbuV0ivA8DeeBOJ5oQxpmHKDdP96lfmT7++l91YX3jhBdPY2JiH0cyN+dzu3bvXVFVV0bZ3v0J6HRijX98rSFrWig2Kk8DXOHW21i3FSeBznDpb647iJPA5Ts2c7ihOAl/j1DGnW4qTwNc4NXO6pTgJfI5Tx5zuKE4CX+PUstYtxUnga5xa1rqlOAl8jlPLWncUJ0E4HPYyTi1r3VKcBKFQCOl02vUw6LSsdUtxEvi8rFWc7ihOAp/j1DGnO4qTwNc4dczpluIk8DVOLWvdUpwEPsepZa07ipPA1zi1rHVLcRL4GqeWtW4pTgKf49Sy1h3FSeBznJo53VGcBIpTbFCcBL7GOTY2huLiYtfDeGApTgLFKTYoTgJf49Sy1i3FSeBjnMYYjI+Pa+Z0SHES+Bhn5qrWitMdxUngY5xjY2MAFKdLipNAcYoNipNAcYoNipPAxzgzx5w6W+uO4iTwMU7NnO4pTgLFKTYoTgLFKTYoTgLFKTYoTgIf49QJIfcUJ4GPcWrmdE9xEihOsUFxEihOsUFxEihOsUFxEihOsUFxEvgYp87Wuhea7UUViURMbe1G+k6TySSi0Sh9uzZkM9Zr1zrQ1dWFbdsez9OoZsZ6bnt6evDPPxcRjcZQVlZGGNlUhfQ6AOyNN5FoThhjGqbcYIyZ8S8ejxsb4vEGK9u1IZux7t+/35SWluZhNHNjPbdffvmlAWDOnTtH2d50Cul1YIy98QJoNtP0p2UtgY/LWh1zuqc4CXy87LzidE9xEvh42XmdEHJPcRJoWSs2KE4CxSk2KE4CxSk2KE4CxSk2KE4CxSk2KE6CUCjkegh0mbO14bBeIq7omSfIxOnT7Jm5wpiP/+MpFIqTwOc4xR3FSaA4xQbFSeBrnCUlJa6H8UBTnAQ+xjkyMqI4HVOcBD7GOTo6isWLF7sexgNNcRL4GqdmTrcUJ4HiFBsUJ4GPceqY0z3FSeBjnDrmdE9xEvgap2ZOtxQngY9xalnrnuIk8DFOzZzuKU4CX+PUMadbipPA1zg1c7qlOAl8jFPHnO4pTgIf49TM6Z7iJPA1Th1zuqU4CXyNUzOnW4qTwMc4dczpnuIk8C3OdDqN8fFxxemY4iTwLc7Mz2LqmNMtxUngW5yjo6MAoJnTMcVJ4FucIyMjABSna4qTwLc4NXMGg+Ik8DVOHXO6pTgJfI1TM6dbipMgcz0RX+LUMWcwKE6CzMzpy6XnNXMGg+Ik0LJWbFCcBL7FOTQ0BAAoLS11PJIHm+IkCEKcR48exWuvvYarV6+ira0tp20NDw8DAJYsWcIYmixQaLYXVCQSMbW1G+k7TSaTiEaj9O3akM1Yu7tv4vLly6irq8/72w/GGHR2dqKz818UFRUhlUohHA6jpqYGy5eXL2ibPT09+Oefi4hGYygrKyOP+D+F9DoA7I03kWhOGGMaptxgjJnxLx6PGxvi8QYr27Uhm7EeOnTIADDt7e15GNFkn376qQFg9uzZY4aGhsyWLVtMNBo1lZWVpqura0Hb/Pzzzw0Ac/78efJoJyuk14Ex9sYLoNlM05+WtQSulrXnz5/H22+/jR07duDgwYNYsmQJiotL8NVXX6G7uxsffvjhgrabOebUstYtxUngIk5jDPbt24eSkhIcPnwYRUVF926rr6/Hnj17cODAAXR1dc1725ljTp0QcktxEriI88cff8T333+P9957D6tWrZpy+/79+zEyMoJDhw7Ne9s6IRQMipPARZwffPAB1q5di7feemva22OxGJ588kkcPHhw3uPSsjYYFCdBvuP8448/8Ntvv+Gdd96Z9YMCu3fvRltbG1pbW+e1/eHhYRQVFaG4uDjXoUoOFCdBvuP8+OOPUVFRgb179856v5deegkAcOTIkXltf3h4WLNmAChOgnzGefPmTRw5cgSvvPIKli1bNut9V69ejaamJnz77bfz2sfQ0JDiDADFSZDPOA8fPoyxsTG8+uqrWd3/+eefR3NzM/r6+rLex/DwsM7UBoDiJMhnnJ999hkaGxtRX1+f1f2fffZZpNNpHDt2LOt9aFkbDIqTIF9xtrW1oaWlBbt37876Mdu3b0dJSQmOHj2a9WMUZzAoToJ8xfn1118DAF5++eWsH1NaWort27fj119/zfoxQ0NDWtYGgOIkyGecTU1NWLt27bwe99RTT+HMmTO4c+dOVvfXzBkMipMgH3FeuXIFiUQCu3btmvdjGxsbkUql8Oeff2Z1f8UZDIqTIB9x/vDDDwCAnTt3zvuxTzzxBADg5MmTWd1fy9pgUJwE+Yjzp59+QlVVFTZv3jzvx1ZVVaG6ujrrODVzBoPiJLAdZzqdxi+//IIdO3bc29d8NTY24sSJE1ndVx9CCAbFSWA7zpaWFty8eRPPPffcgrcRj8dx6dKlrD6MMDg4iKVLly54X8KhOAlsx/nzzz8DQE5xbt26FcDd0OcyODg450cDxT7FSWA7zt9//x3r16+f91soE23ZsgUAcObMmVnvl0qlMDQ0pJkzABQnge04T548iaamppy2sWbNGlRUVOCvv/6a9X6Z90IVp3uKk8BmnJ2dnejo6EBjY2NO2wmFQtiyZcuccQ4ODgKAlrUBoDgJbMaZefsj15kTuLu0bWlpmfWyEQMDAwA0cwaB4iSwGeeJEyewaNEibNu2Ledtbd26FYODg7h06dKM99HMGRyKk8BmnKdPn0YsFqN8YifzNbPZzthm4tTM6Z7iJLAZ59mzZ7P+7uZcMp8uSiaTM95Hy9rgUJwEtuLs7e1FR0cHLc7y8nKsWbNm1h/80rI2OBQnga04z507BwCoq6ujbTMWi2nmLBCKk8BWnJljQ9bMCQDRaBRtbW0znrHVMWdwKE4CW5edP3v2LMrLy1FdXU3bZjQaxeDgIK5duzbt7VrWBofiJLB12flkMolYLLbgb6JMJ3MJu5mWtpllrc1L/0l2FCeBrWVte3s7ampqqNuMxWIAMONJoYGBAZSWlk66MJK4oTgJbMQ5MjKCjo4OepyVlZVYuXLljDNnT08PKioqqPuUhVGcBDbivHTpEowx9DiBu0vbmeLs7e3FihUr6PuU+VOcBDbibG9vBwBs2LCBts2MaDSK1tbWacfb29urmTMgFCeBzThtzJyxWAy3bt2a9sK6PT09mjkDQnES2Ijz4sWLKC8vx8qVK2nbzJjtjK2WtcGhOAlszZw1NTXUt1EyFGdhUJwENuK8fPky1q1bR9veRNXV1Vi6dOmUONPptI45A0RxErDjNMago6OD+smgiUKhEKLR6L3P7mYMDAwgnU5r5gwIxUnAjrOvrw+Dg4PW4gTufl737Nmzk/6tp6cHABRnQChOAnacmc+95vJre3Opq6vD9evXJ52xzcSpZW0wKE4CdpwdHR0AYHXmzHwNbeLS9vr16wCARx991Np+JXuh2V5QkUjE1NZupO80mUzeO2MYdNmM9c6dQSSTSWzYsAErVuQ+63R1deHq1Suor69HScnieT022+d2dHQULS1/obr6f/DII48AALq7b+Ly5ct47LG6vFyOoZBeB4C98SYSzQljTMOUG4wxM/7F43FjQzzeYGW7NmQz1lOnThkA5ptvvqHs89133zXhcNiMjo7O+7HZPrfpdNpUVFSYN954496/ffTRRwaA6e/vn/d+F6KQXgfG2BsvgGYzTX9a1hLYWNauWrUKxcXFlO1NJxQKoa6ubtJJoevXr6OsrEzf5QwIxUlg44SQzePNjPr6+km/Y/vvv/+iqqrKygcfZP4UJ4GNOG2eqc2Ix+Po7+/H33//DeDuN2FsffBB5k9xErDj7OzsRFVVFWVbs9m+fTsA4Pjx4wDuxrl+/Xrr+5XsKE4CZpzDw8Po6+vLy9sZmzZtQiQSwfHjxzEwMIAbN24ozgBRnATMODMfCshHnOFwGE1NTTh27BhOnz4N4L9LBYp7ipOAGWfmgwCZ9x5te/HFF9Ha2oovvvgCAPD444/nZb8yN8VJYCPOfH1KZ9euXQCATz75BNFoFKtXr87LfmVuipOAGeeNGzcA5C/OtWvX4s033wQA7Nu3Ly/7lOwoToJCXtYCwIEDB3Dt2jW8/vrredunzE1xErBnzqVLl+b1cgjhcBhr1qzJ2/4kO4qTgD1z6lshAihOCsUpNihOAvayVnEKoDgp2DNnPk8GSXApTgJWnMYYdHd3o7KykjEsKXCKk4AVZ19fH1KplJUfkpbCozgJWHHeunULAPDQQw/lPCYpfIqTQHGKDYqTgHXZ+UycWtYKoDgpWJed18wpEylOAtaytru7G4DilLsUJwH7mFO/uC6A4qRgxrl8+XKrP4kphUNxEjDj1MkgyVCcBMxjTh1vSobiJGDOnIpTMhQngeIUGxQngeIUGxQnASNOY4xOCMkkipOAEeft27eRSqX0HqfcozgJGHH29fUBACKRCGVMUvgUJ4HiFBsUJ4HiFBsUJwEzzvLycsqYpPApTgJGnP39/QA0c8p/FCeBlrVig+IkUJxig+IkYMVZVFSEsrIy1rCkwClOAlac5eXl97YlojgJWCeEtKSViUKzvaAikYiprd1I32kymUQ0GqVv14ZsxmpMGqdOncLq1atRVbWwK0O3t7djdHQEsdhjC3p8hm/PbZDYGm8i0ZwwxjRMucEYM+NfPB43NsTjDVa2a0M2Yx0bGzMAzPvvv7/g/TzzzDPm6aefXvDjM3x7boPE1ngBNJtp+tOyloB1zKllrUykOAlYx5z6dJBMpDgJNHOKDYqTINdffDfGKE6ZQnGShEKhBc+cQ0NDGB8fV5wyieIkCYfDC45TH92T6ShOklAotOBl7e3btwEAy5cvZw5JCpziJMllWTswMABAccpkipMklzg1c8p0FCdJLsecmZlz2bJlzCFJgVOcJLkccypOmY7iJGEccypOmUhxkmhZK2yKk0TLWmFTnCS5nq1dvHixrmgtkyhOklyPOTVryv0UJ0mux5yKU+6nOElyPeZUnHI/xUmiZa2wKU4SLWuFbdZf3wuFQl0AruRvOCIPpP81xlTe/4+zxiki7mhZKxJQilMkoBSnSEApTpGAUpwiAfX/uZM5UCnDSmYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_batch = next(iter(test_set))\n",
    "img, lbls = test_batch\n",
    "img, lbls = img.to(device), lbls.to(device)\n",
    "# print(img.shape, lbls.shape)\n",
    "\n",
    "output = model.forward(img)\n",
    "#print(output)\n",
    "#print(lbls)\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "output0_coeff = output[0]\n",
    "output0_coeff = output0_coeff.detach().cpu().numpy()\n",
    "lbls0_coeff = lbls[0]\n",
    "lbls0_coeff = lbls0_coeff.detach().cpu().numpy()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#display output[0] curve\n",
    "print(f'Output tensor: {output0_coeff}')\n",
    "print('Output curve: ')\n",
    "ax.plot(x, ((output0_coeff[7]*x**8)+(output0_coeff[6]*x**7)+(output0_coeff[5]*x**6)\n",
    "            +(output0_coeff[4]*x**5)+(output0_coeff[3]*x**4)+(output0_coeff[2]*x**3)\n",
    "            +(output0_coeff[1]*x**2)+(output0_coeff[0]*x**1)),\n",
    "            color='#000000')\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.tick_params(left = False, labelleft = False,\n",
    "                   bottom =  False, labelbottom = False)\n",
    "ax.grid(color='#000001')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#display actual curve\n",
    "print(f'Actual label tensor: {lbls0_coeff}')\n",
    "print('Actual curve: ')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, ((lbls0_coeff[7]*x**8)+(lbls0_coeff[6]*x**7)+(lbls0_coeff[5]*x**6)\n",
    "            +(lbls0_coeff[4]*x**5)+(lbls0_coeff[3]*x**4)+(lbls0_coeff[2]*x**3)\n",
    "            +(lbls0_coeff[1]*x**2)+(lbls0_coeff[0]*x**1)),\n",
    "            color='#000000')\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.tick_params(left = False, labelleft = False,\n",
    "                   bottom =  False, labelbottom = False)\n",
    "ax.grid(color='#000001')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network\n",
    "# model.save('C:\\\\Users\\\\the_3\\\\Desktop\\\\poly-curve-detector\\\\Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    # 'arch': 'vgg16',\n",
    "    # 'input_size': 25088,\n",
    "    # 'output_size': 102,\n",
    "    # 'hidden_units': 4096,\n",
    "    'model': model.to(torch.device('cpu')),\n",
    "    'features': model.features,\n",
    "    'classifier': model.classifier,\n",
    "    # 'optimizer': optimizer.state_dict(),\n",
    "    'state_dict': model.state_dict(),\n",
    "    # 'idx_to_class': {val: key for key, val in image_datasets.class_to_idx.items()}\n",
    "}\n",
    "\n",
    "torch.save(checkpoint,'model/model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): LeakyReLU(negative_slope=0.01)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): LeakyReLU(negative_slope=0.01)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=1568, out_features=4096, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (9): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laod network from save\n",
    "# net_path = root + \"\\\\poly-curve-detector\\\\Model\\\\model_checkpoint.pth\"\n",
    "# new_model = Network()\n",
    "# Network.load_checkpoint(new_model, net_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(path):\n",
    "    '''give absolute path'''\n",
    "    checkpoint = torch.load(path)\n",
    "    model = checkpoint['model']\n",
    "    model.classifier = checkpoint['classifier']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return checkpoint, model\n",
    "\n",
    "checkpoint, model = load_checkpoint('models/model_checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor: [ 5.6838956  -8.467546   -6.5452247   0.66510093 -5.0171356   4.685207\n",
      " -3.2718596  -3.1595328 ]\n",
      "Output curve: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label tensor: [  5 -10  -4   3  -7   7  -9  -7]\n",
      "Actual curve: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loaded network from save\n",
    "test_batch = next(iter(test_set))\n",
    "img, lbls = test_batch\n",
    "# img, lbls = img.to(device), lbls.to(device)\n",
    "# print(img.shape, lbls.shape)\n",
    "\n",
    "output = new_model.forward(img)\n",
    "#print(output)\n",
    "#print(lbls)\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "output0_coeff = output[0]\n",
    "output0_coeff = output0_coeff.detach().cpu().numpy()\n",
    "lbls0_coeff = lbls[0]\n",
    "lbls0_coeff = lbls0_coeff.detach().cpu().numpy()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#display output[0] curve\n",
    "print(f'Output tensor: {output0_coeff}')\n",
    "print('Output curve: ')\n",
    "ax.plot(x, ((output0_coeff[7]*x**8)+(output0_coeff[6]*x**7)+(output0_coeff[5]*x**6)\n",
    "            +(output0_coeff[4]*x**5)+(output0_coeff[3]*x**4)+(output0_coeff[2]*x**3)\n",
    "            +(output0_coeff[1]*x**2)+(output0_coeff[0]*x**1)),\n",
    "            color='#000000')\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.tick_params(left = False, labelleft = False,\n",
    "                   bottom =  False, labelbottom = False)\n",
    "ax.grid(color='#000001')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#display actual curve\n",
    "print(f'Actual label tensor: {lbls0_coeff}')\n",
    "print('Actual curve: ')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(x, ((lbls0_coeff[7]*x**8)+(lbls0_coeff[6]*x**7)+(lbls0_coeff[5]*x**6)\n",
    "            +(lbls0_coeff[4]*x**5)+(lbls0_coeff[3]*x**4)+(lbls0_coeff[2]*x**3)\n",
    "            +(lbls0_coeff[1]*x**2)+(lbls0_coeff[0]*x**1)),\n",
    "            color='#000000')\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.tick_params(left = False, labelleft = False,\n",
    "                   bottom =  False, labelbottom = False)\n",
    "ax.grid(color='#000001')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a1829a56db40c3ca63cc5d173ccaf89ee3791672440d362287656aaeb413643"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
